{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "This notebook contains all data preparations steps for different models used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation for using YOLO bounding boxes\n",
    "\n",
    "We need to convert and reorganize the dataset into YOLO format. This involves:  \n",
    "1. **Creating the required directory structure** (`images/` and `labels/` for `train`, `val`, `test`).  \n",
    "2. **Extracting bounding boxes** from JSON annotations, filtering only rectangles.  \n",
    "3. **Normalizing coordinates** to YOLO format (`class x_center y_center width height`).  \n",
    "4. **Copying images and saving annotations** in the correct locations.  \n",
    "\n",
    "\n",
    "### 1.1. Dataset containing only fractures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "raw_data_dir = \"raw data\"\n",
    "yolo_data_dir = \"data_object_detection_yolo\"\n",
    "\n",
    "# Create YOLO folder structure\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(yolo_data_dir, \"images\", split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(yolo_data_dir, \"labels\", split), exist_ok=True)\n",
    "\n",
    "# Function to convert bounding boxes to YOLO format\n",
    "def convert_bbox_to_yolo(img_w, img_h, bbox):\n",
    "    x_min, y_min = bbox[0]\n",
    "    x_max, y_max = bbox[1]\n",
    "\n",
    "    # Convert to YOLO format\n",
    "    x_center = ((x_min + x_max) / 2) / img_w\n",
    "    y_center = ((y_min + y_max) / 2) / img_h\n",
    "    bbox_width = (x_max - x_min) / img_w\n",
    "    bbox_height = (y_max - y_min) / img_h\n",
    "\n",
    "    return f\"0 {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\"\n",
    "\n",
    "# Process each dataset split\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    img_src_dir = os.path.join(raw_data_dir, split, \"img\")\n",
    "    ann_src_dir = os.path.join(raw_data_dir, split, \"ann\")\n",
    "\n",
    "    img_dest_dir = os.path.join(yolo_data_dir, \"images\", split)\n",
    "    ann_dest_dir = os.path.join(yolo_data_dir, \"labels\", split)\n",
    "\n",
    "    image_files = {os.path.splitext(f)[0]: f for f in os.listdir(img_src_dir) if f.endswith((\".jpg\", \".png\", \".jpeg\"))}\n",
    "\n",
    "    for json_file in os.listdir(ann_src_dir):\n",
    "        if not json_file.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        base_name = json_file.replace(\".jpg.json\", \"\").replace(\".png.json\", \"\").replace(\".jpeg.json\", \"\")\n",
    "\n",
    "        # Find the corresponding image file\n",
    "        if base_name not in image_files:\n",
    "            print(f\"Skipping {json_file}: No matching image found\")\n",
    "            continue\n",
    "\n",
    "        img_name = image_files[base_name]\n",
    "        img_path = os.path.join(img_src_dir, img_name)\n",
    "        json_path = os.path.join(ann_src_dir, json_file)\n",
    "\n",
    "        # Load annotation JSON\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        img_width, img_height = data[\"size\"][\"width\"], data[\"size\"][\"height\"]\n",
    "        yolo_annotations = []\n",
    "\n",
    "        # Process objects (only rectangles)\n",
    "        for obj in data[\"objects\"]:\n",
    "            if obj[\"geometryType\"] == \"rectangle\":\n",
    "                bbox = obj[\"points\"][\"exterior\"]\n",
    "                yolo_annotations.append(convert_bbox_to_yolo(img_width, img_height, bbox))\n",
    "\n",
    "        # Save YOLO annotations\n",
    "        if yolo_annotations:\n",
    "            yolo_label_path = os.path.join(ann_dest_dir, base_name + \".txt\")\n",
    "            with open(yolo_label_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(yolo_annotations))\n",
    "\n",
    "        # Copy image to YOLO dataset\n",
    "        shutil.copy(img_path, img_dest_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that we have the same number of images and annotations. This can also be compared to our `02_raw_data_analysis.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Images</th>\n",
       "      <th>Annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split  Images  Annotations\n",
       "0  train     574          574\n",
       "1    val      82           82\n",
       "2   test      61           61"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_counts = {\"Split\": [], \"Images\": [], \"Annotations\": []}\n",
    "\n",
    "# Count images and annotations in each split\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    img_dir = os.path.join(yolo_data_dir, \"images\", split)\n",
    "    ann_dir = os.path.join(yolo_data_dir, \"labels\", split)\n",
    "\n",
    "    num_images = len([f for f in os.listdir(img_dir) if f.endswith((\".jpg\", \".png\", \".jpeg\"))])\n",
    "    num_annotations = len([f for f in os.listdir(ann_dir) if f.endswith(\".txt\")])\n",
    "\n",
    "    data_counts[\"Split\"].append(split)\n",
    "    data_counts[\"Images\"].append(num_images)\n",
    "    data_counts[\"Annotations\"].append(num_annotations)\n",
    "\n",
    "df_counts = pd.DataFrame(data_counts)\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the new data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_object_detection_yolo/\n",
      "    data.yaml\n",
      "    images/\n",
      "        test/\n",
      "            IMG0003297.jpg\n",
      "            IMG0003298.jpg\n",
      "        train/\n",
      "            IMG0000019.jpg\n",
      "            IMG0000025.jpg\n",
      "        val/\n",
      "            IMG0003733.jpg\n",
      "            IMG0003734.jpg\n",
      "    labels/\n",
      "        train.cache\n",
      "        val.cache\n",
      "        test/\n",
      "            IMG0003297.txt\n",
      "            IMG0003298.txt\n",
      "        train/\n",
      "            IMG0000019.txt\n",
      "            IMG0000025.txt\n",
      "        val/\n",
      "            IMG0003733.txt\n",
      "            IMG0003734.txt\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(yolo_data_dir):\n",
    "    level = root.replace(yolo_data_dir, '').count(os.sep)\n",
    "    indent = ' ' * 4 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    sub_indent = ' ' * 4 * (level + 1)\n",
    "    for f in files[:2]:                                     # Show only first 2 files per folder\n",
    "        print(f\"{sub_indent}{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we need to create the yaml file necessary to use the YOLO model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.yaml created at: data_object_detection_yolo\\data.yaml\n"
     ]
    }
   ],
   "source": [
    "# Define the paths for train, val, and test images\n",
    "data_yaml = {\n",
    "    \"train\": \"images/train\",\n",
    "    \"val\": \"images/val\",\n",
    "    \"test\": \"images/test\",  # Optional\n",
    "    \"nc\": 1,  # Number of classes\n",
    "    \"names\": [\"fractured\"]  # Class names\n",
    "}\n",
    "\n",
    "# Save the updated YAML file\n",
    "yaml_path = os.path.join(\"data_object_detection_yolo\", \"data.yaml\")\n",
    "with open(yaml_path, \"w\") as file:\n",
    "    yaml.dump(data_yaml, file, default_flow_style=False)\n",
    "\n",
    "print(f\"data.yaml created at: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dataset containing a balanced number of fractures/not fractured images\n",
    "\n",
    "This time we will also add random not fractured images to the new dataset and create empty annotation files for those, since they do not have any bounding box information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset conversion completed successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define dataset paths\n",
    "raw_data_dir = \"raw data\"\n",
    "not_fractured_img_dir = os.path.join(raw_data_dir, \"not fractured\", \"img\")\n",
    "not_fractured_ann_dir = os.path.join(raw_data_dir, \"not fractured\", \"ann\")\n",
    "yolo_data_dir = \"data_object_detection_incl_not_fractured_yolo\"\n",
    "\n",
    "# Set a fixed seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Create YOLO folder structure\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(yolo_data_dir, \"images\", split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(yolo_data_dir, \"labels\", split), exist_ok=True)\n",
    "\n",
    "# Function to convert bounding boxes to YOLO format\n",
    "def convert_bbox_to_yolo(img_w, img_h, bbox):\n",
    "    x_min, y_min = bbox[0]\n",
    "    x_max, y_max = bbox[1]\n",
    "\n",
    "    # Convert to YOLO format\n",
    "    x_center = ((x_min + x_max) / 2) / img_w\n",
    "    y_center = ((y_min + y_max) / 2) / img_h\n",
    "    bbox_width = (x_max - x_min) / img_w\n",
    "    bbox_height = (y_max - y_min) / img_h\n",
    "\n",
    "    return f\"0 {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\"\n",
    "\n",
    "# Track used 'not fractured' images across all splits\n",
    "used_not_fractured = set()\n",
    "\n",
    "all_not_fractured = [f for f in os.listdir(not_fractured_img_dir) if f.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "\n",
    "# Process each dataset split\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    img_src_dir = os.path.join(raw_data_dir, split, \"img\")\n",
    "    ann_src_dir = os.path.join(raw_data_dir, split, \"ann\")\n",
    "\n",
    "    img_dest_dir = os.path.join(yolo_data_dir, \"images\", split)\n",
    "    ann_dest_dir = os.path.join(yolo_data_dir, \"labels\", split)\n",
    "\n",
    "    image_files = {os.path.splitext(f)[0]: f for f in os.listdir(img_src_dir) if f.endswith((\".jpg\", \".png\", \".jpeg\"))}\n",
    "    fractured_count = len(image_files)\n",
    "\n",
    "    # Process fractured images\n",
    "    for json_file in os.listdir(ann_src_dir):\n",
    "        if not json_file.endswith(\".json\"):\n",
    "            continue\n",
    "        \n",
    "        base_name = json_file.replace(\".jpg.json\", \"\").replace(\".png.json\", \"\").replace(\".jpeg.json\", \"\")\n",
    "\n",
    "        if base_name not in image_files:\n",
    "            print(f\"Skipping {json_file}: No matching image found\")\n",
    "            continue\n",
    "\n",
    "        img_name = image_files[base_name]\n",
    "        img_path = os.path.join(img_src_dir, img_name)\n",
    "        json_path = os.path.join(ann_src_dir, json_file)\n",
    "\n",
    "        # Load annotation JSON\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        img_width, img_height = data[\"size\"][\"width\"], data[\"size\"][\"height\"]\n",
    "        yolo_annotations = []\n",
    "\n",
    "        # Process objects (only rectangles)\n",
    "        for obj in data[\"objects\"]:\n",
    "            if obj[\"geometryType\"] == \"rectangle\":\n",
    "                bbox = obj[\"points\"][\"exterior\"]\n",
    "                yolo_annotations.append(convert_bbox_to_yolo(img_width, img_height, bbox))\n",
    "\n",
    "        # Save YOLO annotations\n",
    "        if yolo_annotations:\n",
    "            yolo_label_path = os.path.join(ann_dest_dir, base_name + \".txt\")\n",
    "            with open(yolo_label_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(yolo_annotations))\n",
    "\n",
    "        # Copy image to YOLO dataset\n",
    "        shutil.copy(img_path, img_dest_dir)\n",
    "\n",
    "    # Process 'not fractured' images\n",
    "    available_images = list(set(all_not_fractured) - used_not_fractured)\n",
    "\n",
    "    # Ensure there are enough images to sample\n",
    "    num_to_sample = min(fractured_count, len(available_images))\n",
    "    if num_to_sample == 0:\n",
    "        print(f\"Warning: No 'not fractured' images available for {split}\")\n",
    "        continue\n",
    "\n",
    "    selected_images = random.sample(available_images, num_to_sample)\n",
    "\n",
    "    for img_name in selected_images:\n",
    "        used_not_fractured.add(img_name)  # Mark image as used\n",
    "\n",
    "        img_path = os.path.join(not_fractured_img_dir, img_name)\n",
    "\n",
    "        # Copy image\n",
    "        shutil.copy(img_path, img_dest_dir)\n",
    "\n",
    "        # Create empty annotation file\n",
    "        yolo_label_path = os.path.join(ann_dest_dir, img_name + \".txt\")\n",
    "        with open(yolo_label_path, \"w\") as f:\n",
    "            pass  # Empty file\n",
    "\n",
    "print(\"Dataset conversion completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that we have the same number of images and annotations. This can also be compared to our `02_raw_data_analysis.ipynb`, and should now contain twice the previous files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Images</th>\n",
       "      <th>Annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>1610</td>\n",
       "      <td>1610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split  Images  Annotations\n",
       "0  train    1610         1610\n",
       "1    val     245          245\n",
       "2   test     181          181"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_counts = {\"Split\": [], \"Images\": [], \"Annotations\": []}\n",
    "\n",
    "# Count images and annotations in each split\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    img_dir = os.path.join(yolo_data_dir, \"images\", split)\n",
    "    ann_dir = os.path.join(yolo_data_dir, \"labels\", split)\n",
    "\n",
    "    num_images = len([f for f in os.listdir(img_dir) if f.endswith((\".jpg\", \".png\", \".jpeg\"))])\n",
    "    num_annotations = len([f for f in os.listdir(ann_dir) if f.endswith(\".txt\")])\n",
    "\n",
    "    data_counts[\"Split\"].append(split)\n",
    "    data_counts[\"Images\"].append(num_images)\n",
    "    data_counts[\"Annotations\"].append(num_annotations)\n",
    "\n",
    "df_counts = pd.DataFrame(data_counts)\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we again create the yaml file necessary to use the YOLO model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.yaml created at: data_object_detection_incl_not_fractured_yolo\\data.yaml\n"
     ]
    }
   ],
   "source": [
    "# Define the paths for train, val, and test images\n",
    "data_yaml = {\n",
    "    \"train\": \"images/train\",\n",
    "    \"val\": \"images/val\",\n",
    "    \"test\": \"images/test\",  # Optional\n",
    "    \"nc\": 1,  # Number of classes\n",
    "    \"names\": [\"fractured\"]  # Class names\n",
    "}\n",
    "\n",
    "# Save the updated YAML file\n",
    "yaml_path = os.path.join(yolo_data_dir, \"data.yaml\")\n",
    "with open(yaml_path, \"w\") as file:\n",
    "    yaml.dump(data_yaml, file, default_flow_style=False)\n",
    "\n",
    "print(f\"data.yaml created at: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
