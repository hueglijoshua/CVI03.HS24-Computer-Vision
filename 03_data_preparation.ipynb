{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "This notebook contains all data preparations steps for different models used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation for using YOLO bounding boxes\n",
    "\n",
    "We need to convert and reorganize the dataset into YOLO format. This involves:  \n",
    "1. **Creating the required directory structure** (`images/` and `labels/` for `train`, `val`, `test`).  \n",
    "2. **Extracting bounding boxes** from JSON annotations, filtering only rectangles.  \n",
    "3. **Normalizing coordinates** to YOLO format (`class x_center y_center width height`).  \n",
    "4. **Copying images and saving annotations** in the correct locations.  \n",
    "\n",
    "\n",
    "### 1.1. Dataset containing only fractures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "raw_data_dir = \"raw data\"\n",
    "yolo_data_dir = \"data_object_detection_yolo\"\n",
    "\n",
    "# Create YOLO folder structure\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(yolo_data_dir, \"images\", split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(yolo_data_dir, \"labels\", split), exist_ok=True)\n",
    "\n",
    "# Function to convert bounding boxes to YOLO format\n",
    "def convert_bbox_to_yolo(img_w, img_h, bbox):\n",
    "    x_min, y_min = bbox[0]\n",
    "    x_max, y_max = bbox[1]\n",
    "\n",
    "    # Convert to YOLO format\n",
    "    x_center = ((x_min + x_max) / 2) / img_w\n",
    "    y_center = ((y_min + y_max) / 2) / img_h\n",
    "    bbox_width = (x_max - x_min) / img_w\n",
    "    bbox_height = (y_max - y_min) / img_h\n",
    "\n",
    "    return f\"0 {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\"\n",
    "\n",
    "# Process each dataset split\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    img_src_dir = os.path.join(raw_data_dir, split, \"img\")\n",
    "    ann_src_dir = os.path.join(raw_data_dir, split, \"ann\")\n",
    "\n",
    "    img_dest_dir = os.path.join(yolo_data_dir, \"images\", split)\n",
    "    ann_dest_dir = os.path.join(yolo_data_dir, \"labels\", split)\n",
    "\n",
    "    image_files = {os.path.splitext(f)[0]: f for f in os.listdir(img_src_dir) if f.endswith((\".jpg\", \".png\", \".jpeg\"))}\n",
    "\n",
    "    for json_file in os.listdir(ann_src_dir):\n",
    "        if not json_file.endswith(\".json\"):\n",
    "            continue\n",
    "\n",
    "        base_name = json_file.replace(\".jpg.json\", \"\").replace(\".png.json\", \"\").replace(\".jpeg.json\", \"\")\n",
    "\n",
    "        # Find the corresponding image file\n",
    "        if base_name not in image_files:\n",
    "            print(f\"Skipping {json_file}: No matching image found\")\n",
    "            continue\n",
    "\n",
    "        img_name = image_files[base_name]\n",
    "        img_path = os.path.join(img_src_dir, img_name)\n",
    "        json_path = os.path.join(ann_src_dir, json_file)\n",
    "\n",
    "        # Load annotation JSON\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        img_width, img_height = data[\"size\"][\"width\"], data[\"size\"][\"height\"]\n",
    "        yolo_annotations = []\n",
    "\n",
    "        # Process objects (only rectangles)\n",
    "        for obj in data[\"objects\"]:\n",
    "            if obj[\"geometryType\"] == \"rectangle\":\n",
    "                bbox = obj[\"points\"][\"exterior\"]\n",
    "                yolo_annotations.append(convert_bbox_to_yolo(img_width, img_height, bbox))\n",
    "\n",
    "        # Save YOLO annotations\n",
    "        if yolo_annotations:\n",
    "            yolo_label_path = os.path.join(ann_dest_dir, base_name + \".txt\")\n",
    "            with open(yolo_label_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(yolo_annotations))\n",
    "\n",
    "        # Copy image to YOLO dataset\n",
    "        shutil.copy(img_path, img_dest_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that we have the same number of images and annotations. This can also be compared to our `02_raw_data_analysis.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Images</th>\n",
       "      <th>Annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split  Images  Annotations\n",
       "0  train     574          574\n",
       "1    val      82           82\n",
       "2   test      61           61"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_counts = {\"Split\": [], \"Images\": [], \"Annotations\": []}\n",
    "\n",
    "# Count images and annotations in each split\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    img_dir = os.path.join(yolo_data_dir, \"images\", split)\n",
    "    ann_dir = os.path.join(yolo_data_dir, \"labels\", split)\n",
    "\n",
    "    num_images = len([f for f in os.listdir(img_dir) if f.endswith((\".jpg\", \".png\", \".jpeg\"))])\n",
    "    num_annotations = len([f for f in os.listdir(ann_dir) if f.endswith(\".txt\")])\n",
    "\n",
    "    data_counts[\"Split\"].append(split)\n",
    "    data_counts[\"Images\"].append(num_images)\n",
    "    data_counts[\"Annotations\"].append(num_annotations)\n",
    "\n",
    "df_counts = pd.DataFrame(data_counts)\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display the new data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_object_detection_yolo/\n",
      "    data.yaml\n",
      "    images/\n",
      "        test/\n",
      "            IMG0003297.jpg\n",
      "            IMG0003298.jpg\n",
      "        train/\n",
      "            IMG0000019.jpg\n",
      "            IMG0000025.jpg\n",
      "        val/\n",
      "            IMG0003733.jpg\n",
      "            IMG0003734.jpg\n",
      "    labels/\n",
      "        train.cache\n",
      "        val.cache\n",
      "        test/\n",
      "            IMG0003297.txt\n",
      "            IMG0003298.txt\n",
      "        train/\n",
      "            IMG0000019.txt\n",
      "            IMG0000025.txt\n",
      "        val/\n",
      "            IMG0003733.txt\n",
      "            IMG0003734.txt\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(yolo_data_dir):\n",
    "    level = root.replace(yolo_data_dir, '').count(os.sep)\n",
    "    indent = ' ' * 4 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    sub_indent = ' ' * 4 * (level + 1)\n",
    "    for f in files[:2]:                                     # Show only first 2 files per folder\n",
    "        print(f\"{sub_indent}{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we need to create the yaml file necessary to use the YOLO model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.yaml created at: data_object_detection_yolo\\data.yaml\n"
     ]
    }
   ],
   "source": [
    "# Define the paths for train, val, and test images\n",
    "data_yaml = {\n",
    "    \"train\": \"images/train\",\n",
    "    \"val\": \"images/val\",\n",
    "    \"test\": \"images/test\",  # Optional\n",
    "    \"nc\": 1,  # Number of classes\n",
    "    \"names\": [\"fractured\"]  # Class names\n",
    "}\n",
    "\n",
    "# Save the updated YAML file\n",
    "yaml_path = os.path.join(\"data_object_detection_yolo\", \"data.yaml\")\n",
    "with open(yaml_path, \"w\") as file:\n",
    "    yaml.dump(data_yaml, file, default_flow_style=False)\n",
    "\n",
    "print(f\"data.yaml created at: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dataset containing a balanced number of fractures/not fractured images\n",
    "\n",
    "This time we will also add random not fractured images to the new dataset and create empty annotation files for those, since they do not have any bounding box information. While training a model, we encountered a corrupt image from the \"not fractured\" folder, therefore, we check for valid images when creating the new dataset directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupt image skipped: IMG0004028.jpg - Error: image file is truncated (20 bytes not processed)\n",
      "Corrupt image skipped: IMG0004029.jpg - Error: image file is truncated (22 bytes not processed)\n",
      "Corrupt image skipped: IMG0004036.jpg - Error: image file is truncated (14 bytes not processed)\n",
      "Corrupt image skipped: IMG0004070.jpg - Error: image file is truncated (41 bytes not processed)\n",
      "Corrupt image skipped: IMG0004073.jpg - Error: image file is truncated (3 bytes not processed)\n",
      "Corrupt image skipped: IMG0004076.jpg - Error: image file is truncated (0 bytes not processed)\n",
      "Corrupt image skipped: IMG0004079.jpg - Error: image file is truncated (24 bytes not processed)\n",
      "Corrupt image skipped: IMG0004084.jpg - Error: image file is truncated (5 bytes not processed)\n",
      "Corrupt image skipped: IMG0004092.jpg - Error: image file is truncated (3 bytes not processed)\n",
      "Corrupt image skipped: IMG0004098.jpg - Error: image file is truncated (17 bytes not processed)\n",
      "Corrupt image skipped: IMG0004100.jpg - Error: image file is truncated (15 bytes not processed)\n",
      "Corrupt image skipped: IMG0004109.jpg - Error: image file is truncated (5 bytes not processed)\n",
      "Corrupt image skipped: IMG0004119.jpg - Error: image file is truncated (6 bytes not processed)\n",
      "Corrupt image skipped: IMG0004120.jpg - Error: image file is truncated (8 bytes not processed)\n",
      "Corrupt image skipped: IMG0004121.jpg - Error: image file is truncated (40 bytes not processed)\n",
      "Corrupt image skipped: IMG0004122.jpg - Error: image file is truncated (26 bytes not processed)\n",
      "Corrupt image skipped: IMG0004123.jpg - Error: image file is truncated (17 bytes not processed)\n",
      "Corrupt image skipped: IMG0004129.jpg - Error: image file is truncated (6 bytes not processed)\n",
      "Corrupt image skipped: IMG0004130.jpg - Error: image file is truncated (8 bytes not processed)\n",
      "Corrupt image skipped: IMG0004134.jpg - Error: image file is truncated (1 bytes not processed)\n",
      "Corrupt image skipped: IMG0004142.jpg - Error: image file is truncated (32 bytes not processed)\n",
      "Corrupt image skipped: IMG0004143.jpg - Error: image file is truncated (10 bytes not processed)\n",
      "Corrupt image skipped: IMG0004145.jpg - Error: image file is truncated (10 bytes not processed)\n",
      "Corrupt image skipped: IMG0004148.jpg - Error: image file is truncated (14 bytes not processed)\n",
      "Corrupt image skipped: IMG0004149.jpg - Error: image file is truncated (33 bytes not processed)\n",
      "Corrupt image skipped: IMG0004154.jpg - Error: image file is truncated (22 bytes not processed)\n",
      "Corrupt image skipped: IMG0004155.jpg - Error: image file is truncated (18 bytes not processed)\n",
      "Corrupt image skipped: IMG0004159.jpg - Error: image file is truncated (8 bytes not processed)\n",
      "Corrupt image skipped: IMG0004169.jpg - Error: image file is truncated (14 bytes not processed)\n",
      "Corrupt image skipped: IMG0004170.jpg - Error: image file is truncated (11 bytes not processed)\n",
      "Corrupt image skipped: IMG0004173.jpg - Error: image file is truncated (0 bytes not processed)\n",
      "Corrupt image skipped: IMG0004174.jpg - Error: image file is truncated (4 bytes not processed)\n",
      "Corrupt image skipped: IMG0004177.jpg - Error: image file is truncated (34 bytes not processed)\n",
      "Corrupt image skipped: IMG0004189.jpg - Error: image file is truncated (16 bytes not processed)\n",
      "Corrupt image skipped: IMG0004194.jpg - Error: image file is truncated (10 bytes not processed)\n",
      "Corrupt image skipped: IMG0004226.jpg - Error: image file is truncated (23 bytes not processed)\n",
      "Corrupt image skipped: IMG0004227.jpg - Error: image file is truncated (30 bytes not processed)\n",
      "Corrupt image skipped: IMG0004228.jpg - Error: image file is truncated (17 bytes not processed)\n",
      "Corrupt image skipped: IMG0004251.jpg - Error: image file is truncated (19 bytes not processed)\n",
      "Corrupt image skipped: IMG0004252.jpg - Error: image file is truncated (67 bytes not processed)\n",
      "Corrupt image skipped: IMG0004255.jpg - Error: image file is truncated (20 bytes not processed)\n",
      "Corrupt image skipped: IMG0004256.jpg - Error: image file is truncated (66 bytes not processed)\n",
      "Corrupt image skipped: IMG0004258.jpg - Error: image file is truncated (0 bytes not processed)\n",
      "Corrupt image skipped: IMG0004259.jpg - Error: image file is truncated (7 bytes not processed)\n",
      "Corrupt image skipped: IMG0004263.jpg - Error: image file is truncated (24 bytes not processed)\n",
      "Corrupt image skipped: IMG0004273.jpg - Error: image file is truncated (8 bytes not processed)\n",
      "Corrupt image skipped: IMG0004275.jpg - Error: image file is truncated (24 bytes not processed)\n",
      "Corrupt image skipped: IMG0004278.jpg - Error: image file is truncated (29 bytes not processed)\n",
      "Corrupt image skipped: IMG0004279.jpg - Error: image file is truncated (5 bytes not processed)\n",
      "Corrupt image skipped: IMG0004285.jpg - Error: image file is truncated (9 bytes not processed)\n",
      "Corrupt image skipped: IMG0004286.jpg - Error: image file is truncated (46 bytes not processed)\n",
      "Corrupt image skipped: IMG0004288.jpg - Error: image file is truncated (1 bytes not processed)\n",
      "Corrupt image skipped: IMG0004290.jpg - Error: image file is truncated (54 bytes not processed)\n",
      "Corrupt image skipped: IMG0004291.jpg - Error: image file is truncated (13 bytes not processed)\n",
      "Corrupt image skipped: IMG0004297.jpg - Error: image file is truncated (5 bytes not processed)\n",
      "Corrupt image skipped: IMG0004298.jpg - Error: image file is truncated (19 bytes not processed)\n",
      "Corrupt image skipped: IMG0004304.jpg - Error: image file is truncated (22 bytes not processed)\n",
      "Corrupt image skipped: IMG0004308.jpg - Error: image file is truncated (40 bytes not processed)\n",
      "Corrupt image skipped: IMG0004347.jpg - Error: image file is truncated (40 bytes not processed)\n",
      "Dataset conversion completed successfully. Corrupt images were skipped.\n"
     ]
    }
   ],
   "source": [
    "# Define dataset paths\n",
    "raw_data_dir = \"raw data\"\n",
    "not_fractured_img_dir = os.path.join(raw_data_dir, \"not fractured\", \"img\")\n",
    "not_fractured_ann_dir = os.path.join(raw_data_dir, \"not fractured\", \"ann\")\n",
    "yolo_data_dir = \"data_object_detection_incl_not_fractured_yolo\"\n",
    "\n",
    "# Set a fixed seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Create YOLO folder structure\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(yolo_data_dir, \"images\", split), exist_ok=True)\n",
    "    os.makedirs(os.path.join(yolo_data_dir, \"labels\", split), exist_ok=True)\n",
    "\n",
    "# Cache for storing valid/corrupt image results\n",
    "valid_images_cache = {}\n",
    "corrupt_images_logged = set()  # Store logged corrupt images to prevent duplicate messages\n",
    "\n",
    "def is_valid_image(img_path):\n",
    "    \"\"\"Check if an image is valid and store the result in a cache.\"\"\"\n",
    "    if img_path in valid_images_cache:\n",
    "        return valid_images_cache[img_path]\n",
    "\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            img.verify()  # Check if image format is correct\n",
    "        with Image.open(img_path) as img:  \n",
    "            img.convert(\"RGB\")  # Try to fully load image (catches deeper corruption)\n",
    "        valid_images_cache[img_path] = True\n",
    "        return True\n",
    "    except (IOError, SyntaxError, OSError) as e:\n",
    "        img_name = os.path.basename(img_path)  # Extract filename only\n",
    "        if img_name not in corrupt_images_logged:\n",
    "            print(f\"Corrupt image skipped: {img_name} - Error: {e}\")\n",
    "            corrupt_images_logged.add(img_name)  # Mark as logged to avoid duplicates\n",
    "        valid_images_cache[img_path] = False\n",
    "        return False\n",
    "\n",
    "# Track used 'not fractured' images across all splits\n",
    "used_not_fractured = set()\n",
    "\n",
    "# Get all 'not fractured' images and filter out corrupted ones\n",
    "all_not_fractured = [\n",
    "    f for f in os.listdir(not_fractured_img_dir) \n",
    "    if f.endswith((\".jpg\", \".png\", \".jpeg\")) and is_valid_image(os.path.join(not_fractured_img_dir, f))\n",
    "]\n",
    "\n",
    "# Process each dataset split\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    img_src_dir = os.path.join(raw_data_dir, split, \"img\")\n",
    "    ann_src_dir = os.path.join(raw_data_dir, split, \"ann\")\n",
    "\n",
    "    img_dest_dir = os.path.join(yolo_data_dir, \"images\", split)\n",
    "    ann_dest_dir = os.path.join(yolo_data_dir, \"labels\", split)\n",
    "\n",
    "    image_files = {\n",
    "        os.path.splitext(f)[0]: f \n",
    "        for f in os.listdir(img_src_dir) \n",
    "        if f.endswith((\".jpg\", \".png\", \".jpeg\")) and is_valid_image(os.path.join(img_src_dir, f))\n",
    "    }\n",
    "    fractured_count = len(image_files)\n",
    "\n",
    "    # Process fractured images\n",
    "    for json_file in os.listdir(ann_src_dir):\n",
    "        if not json_file.endswith(\".json\"):\n",
    "            continue\n",
    "        \n",
    "        base_name = json_file.replace(\".jpg.json\", \"\").replace(\".png.json\", \"\").replace(\".jpeg.json\", \"\")\n",
    "\n",
    "        if base_name not in image_files:\n",
    "            print(f\"Skipping {json_file}: No matching valid image found\")\n",
    "            continue\n",
    "\n",
    "        img_name = image_files[base_name]\n",
    "        img_path = os.path.join(img_src_dir, img_name)\n",
    "        json_path = os.path.join(ann_src_dir, json_file)\n",
    "\n",
    "        # Load annotation JSON\n",
    "        with open(json_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        img_width, img_height = data[\"size\"][\"width\"], data[\"size\"][\"height\"]\n",
    "        yolo_annotations = []\n",
    "\n",
    "        # Process objects (only rectangles)\n",
    "        for obj in data[\"objects\"]:\n",
    "            if obj[\"geometryType\"] == \"rectangle\":\n",
    "                bbox = obj[\"points\"][\"exterior\"]\n",
    "                yolo_annotations.append(\n",
    "                    f\"0 {(bbox[0][0] + bbox[1][0]) / 2 / img_width:.6f} \"\n",
    "                    f\"{(bbox[0][1] + bbox[1][1]) / 2 / img_height:.6f} \"\n",
    "                    f\"{(bbox[1][0] - bbox[0][0]) / img_width:.6f} \"\n",
    "                    f\"{(bbox[1][1] - bbox[0][1]) / img_height:.6f}\"\n",
    "                )\n",
    "\n",
    "        # Save YOLO annotations\n",
    "        if yolo_annotations:\n",
    "            yolo_label_path = os.path.join(ann_dest_dir, base_name + \".txt\")\n",
    "            with open(yolo_label_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(yolo_annotations))\n",
    "\n",
    "        # Copy image to YOLO dataset\n",
    "        shutil.copy(img_path, img_dest_dir)\n",
    "\n",
    "    # Process 'not fractured' images\n",
    "    available_images = list(set(all_not_fractured) - used_not_fractured)\n",
    "\n",
    "    # Ensure there are enough images to sample\n",
    "    num_to_sample = min(fractured_count, len(available_images))\n",
    "    if num_to_sample == 0:\n",
    "        print(f\"Warning: No valid 'not fractured' images available for {split}\")\n",
    "        continue\n",
    "\n",
    "    selected_images = random.sample(available_images, num_to_sample)\n",
    "\n",
    "    for img_name in selected_images:\n",
    "        used_not_fractured.add(img_name)  # Mark image as used\n",
    "\n",
    "        img_path = os.path.join(not_fractured_img_dir, img_name)\n",
    "\n",
    "        # Copy valid image\n",
    "        shutil.copy(img_path, img_dest_dir)\n",
    "\n",
    "        # Create empty annotation file\n",
    "        yolo_label_path = os.path.join(ann_dest_dir, os.path.splitext(img_name)[0] + \".txt\")\n",
    "        with open(yolo_label_path, \"w\") as f:\n",
    "            pass  # Empty file\n",
    "\n",
    "print(\"Dataset conversion completed successfully. Corrupt images were skipped.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that we have the same number of images and annotations. This can also be compared to our `02_raw_data_analysis.ipynb`, and should now contain twice the previous files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Images</th>\n",
       "      <th>Annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>1148</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split  Images  Annotations\n",
       "0  train    1148         1148\n",
       "1    val     164          164\n",
       "2   test     122          122"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_counts = {\"Split\": [], \"Images\": [], \"Annotations\": []}\n",
    "\n",
    "# Count images and annotations in each split\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    img_dir = os.path.join(yolo_data_dir, \"images\", split)\n",
    "    ann_dir = os.path.join(yolo_data_dir, \"labels\", split)\n",
    "\n",
    "    num_images = len([f for f in os.listdir(img_dir) if f.endswith((\".jpg\", \".png\", \".jpeg\"))])\n",
    "    num_annotations = len([f for f in os.listdir(ann_dir) if f.endswith(\".txt\")])\n",
    "\n",
    "    data_counts[\"Split\"].append(split)\n",
    "    data_counts[\"Images\"].append(num_images)\n",
    "    data_counts[\"Annotations\"].append(num_annotations)\n",
    "\n",
    "df_counts = pd.DataFrame(data_counts)\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we again create the yaml file necessary to use the YOLO model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.yaml created at: data_object_detection_incl_not_fractured_yolo\\data.yaml\n"
     ]
    }
   ],
   "source": [
    "# Define the paths for train, val, and test images\n",
    "data_yaml = {\n",
    "    \"train\": \"images/train\",\n",
    "    \"val\": \"images/val\",\n",
    "    \"test\": \"images/test\",  # Optional\n",
    "    \"nc\": 1,  # Number of classes\n",
    "    \"names\": [\"fractured\"]  # Class names\n",
    "}\n",
    "\n",
    "# Save the updated YAML file\n",
    "yaml_path = os.path.join(yolo_data_dir, \"data.yaml\")\n",
    "with open(yaml_path, \"w\") as file:\n",
    "    yaml.dump(data_yaml, file, default_flow_style=False)\n",
    "\n",
    "print(f\"data.yaml created at: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupt image skipped: IMG0004028.jpg - Error: image file is truncated (20 bytes not processed)\n",
      "Corrupt image skipped: IMG0004029.jpg - Error: image file is truncated (22 bytes not processed)\n",
      "Corrupt image skipped: IMG0004036.jpg - Error: image file is truncated (14 bytes not processed)\n",
      "Corrupt image skipped: IMG0004070.jpg - Error: image file is truncated (41 bytes not processed)\n",
      "Corrupt image skipped: IMG0004073.jpg - Error: image file is truncated (3 bytes not processed)\n",
      "Corrupt image skipped: IMG0004076.jpg - Error: image file is truncated (0 bytes not processed)\n",
      "Corrupt image skipped: IMG0004079.jpg - Error: image file is truncated (24 bytes not processed)\n",
      "Corrupt image skipped: IMG0004084.jpg - Error: image file is truncated (5 bytes not processed)\n",
      "Corrupt image skipped: IMG0004092.jpg - Error: image file is truncated (3 bytes not processed)\n",
      "Corrupt image skipped: IMG0004098.jpg - Error: image file is truncated (17 bytes not processed)\n",
      "Corrupt image skipped: IMG0004100.jpg - Error: image file is truncated (15 bytes not processed)\n",
      "Corrupt image skipped: IMG0004109.jpg - Error: image file is truncated (5 bytes not processed)\n",
      "Corrupt image skipped: IMG0004119.jpg - Error: image file is truncated (6 bytes not processed)\n",
      "Corrupt image skipped: IMG0004120.jpg - Error: image file is truncated (8 bytes not processed)\n",
      "Corrupt image skipped: IMG0004121.jpg - Error: image file is truncated (40 bytes not processed)\n",
      "Corrupt image skipped: IMG0004122.jpg - Error: image file is truncated (26 bytes not processed)\n",
      "Corrupt image skipped: IMG0004123.jpg - Error: image file is truncated (17 bytes not processed)\n",
      "Corrupt image skipped: IMG0004129.jpg - Error: image file is truncated (6 bytes not processed)\n",
      "Corrupt image skipped: IMG0004130.jpg - Error: image file is truncated (8 bytes not processed)\n",
      "Corrupt image skipped: IMG0004134.jpg - Error: image file is truncated (1 bytes not processed)\n",
      "Corrupt image skipped: IMG0004142.jpg - Error: image file is truncated (32 bytes not processed)\n",
      "Corrupt image skipped: IMG0004143.jpg - Error: image file is truncated (10 bytes not processed)\n",
      "Corrupt image skipped: IMG0004145.jpg - Error: image file is truncated (10 bytes not processed)\n",
      "Corrupt image skipped: IMG0004148.jpg - Error: image file is truncated (14 bytes not processed)\n",
      "Corrupt image skipped: IMG0004149.jpg - Error: image file is truncated (33 bytes not processed)\n",
      "Corrupt image skipped: IMG0004154.jpg - Error: image file is truncated (22 bytes not processed)\n",
      "Corrupt image skipped: IMG0004155.jpg - Error: image file is truncated (18 bytes not processed)\n",
      "Corrupt image skipped: IMG0004159.jpg - Error: image file is truncated (8 bytes not processed)\n",
      "Corrupt image skipped: IMG0004169.jpg - Error: image file is truncated (14 bytes not processed)\n",
      "Corrupt image skipped: IMG0004170.jpg - Error: image file is truncated (11 bytes not processed)\n",
      "Corrupt image skipped: IMG0004173.jpg - Error: image file is truncated (0 bytes not processed)\n",
      "Corrupt image skipped: IMG0004174.jpg - Error: image file is truncated (4 bytes not processed)\n",
      "Corrupt image skipped: IMG0004177.jpg - Error: image file is truncated (34 bytes not processed)\n",
      "Corrupt image skipped: IMG0004189.jpg - Error: image file is truncated (16 bytes not processed)\n",
      "Corrupt image skipped: IMG0004194.jpg - Error: image file is truncated (10 bytes not processed)\n",
      "Corrupt image skipped: IMG0004226.jpg - Error: image file is truncated (23 bytes not processed)\n",
      "Corrupt image skipped: IMG0004227.jpg - Error: image file is truncated (30 bytes not processed)\n",
      "Corrupt image skipped: IMG0004228.jpg - Error: image file is truncated (17 bytes not processed)\n",
      "Corrupt image skipped: IMG0004251.jpg - Error: image file is truncated (19 bytes not processed)\n",
      "Corrupt image skipped: IMG0004252.jpg - Error: image file is truncated (67 bytes not processed)\n",
      "Corrupt image skipped: IMG0004255.jpg - Error: image file is truncated (20 bytes not processed)\n",
      "Corrupt image skipped: IMG0004256.jpg - Error: image file is truncated (66 bytes not processed)\n",
      "Corrupt image skipped: IMG0004258.jpg - Error: image file is truncated (0 bytes not processed)\n",
      "Corrupt image skipped: IMG0004259.jpg - Error: image file is truncated (7 bytes not processed)\n",
      "Corrupt image skipped: IMG0004263.jpg - Error: image file is truncated (24 bytes not processed)\n",
      "Corrupt image skipped: IMG0004273.jpg - Error: image file is truncated (8 bytes not processed)\n",
      "Corrupt image skipped: IMG0004275.jpg - Error: image file is truncated (24 bytes not processed)\n",
      "Corrupt image skipped: IMG0004278.jpg - Error: image file is truncated (29 bytes not processed)\n",
      "Corrupt image skipped: IMG0004279.jpg - Error: image file is truncated (5 bytes not processed)\n",
      "Corrupt image skipped: IMG0004285.jpg - Error: image file is truncated (9 bytes not processed)\n",
      "Corrupt image skipped: IMG0004286.jpg - Error: image file is truncated (46 bytes not processed)\n",
      "Corrupt image skipped: IMG0004288.jpg - Error: image file is truncated (1 bytes not processed)\n",
      "Corrupt image skipped: IMG0004290.jpg - Error: image file is truncated (54 bytes not processed)\n",
      "Corrupt image skipped: IMG0004291.jpg - Error: image file is truncated (13 bytes not processed)\n",
      "Corrupt image skipped: IMG0004297.jpg - Error: image file is truncated (5 bytes not processed)\n",
      "Corrupt image skipped: IMG0004298.jpg - Error: image file is truncated (19 bytes not processed)\n",
      "Corrupt image skipped: IMG0004304.jpg - Error: image file is truncated (22 bytes not processed)\n",
      "Corrupt image skipped: IMG0004308.jpg - Error: image file is truncated (40 bytes not processed)\n",
      "Corrupt image skipped: IMG0004347.jpg - Error: image file is truncated (40 bytes not processed)\n",
      "Dataset conversion for image classification completed successfully. Corrupt images were skipped.\n"
     ]
    }
   ],
   "source": [
    "# Define dataset paths\n",
    "raw_data_dir = \"raw data\"\n",
    "not_fractured_img_dir = os.path.join(raw_data_dir, \"not fractured\", \"img\")\n",
    "classification_data_dir = \"data_image_classification\"\n",
    "\n",
    "# Set a fixed seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Create classification folder structure\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    os.makedirs(os.path.join(classification_data_dir, split, \"fractured\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(classification_data_dir, split, \"not_fractured\"), exist_ok=True)\n",
    "\n",
    "# Cache for storing valid/corrupt image results\n",
    "valid_images_cache = {}\n",
    "corrupt_images_logged = set()\n",
    "\n",
    "def is_valid_image(img_path):\n",
    "    \"\"\"Check if an image is valid and store the result in a cache.\"\"\"\n",
    "    if img_path in valid_images_cache:\n",
    "        return valid_images_cache[img_path]\n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            img.verify()\n",
    "        with Image.open(img_path) as img:\n",
    "            img.convert(\"RGB\")\n",
    "        valid_images_cache[img_path] = True\n",
    "        return True\n",
    "    except (IOError, SyntaxError, OSError) as e:\n",
    "        img_name = os.path.basename(img_path)\n",
    "        if img_name not in corrupt_images_logged:\n",
    "            print(f\"Corrupt image skipped: {img_name} - Error: {e}\")\n",
    "            corrupt_images_logged.add(img_name)\n",
    "        valid_images_cache[img_path] = False\n",
    "        return False\n",
    "\n",
    "# Track used 'not fractured' images across all splits\n",
    "used_not_fractured = set()\n",
    "\n",
    "# Get all 'not fractured' images and filter out corrupted ones\n",
    "all_not_fractured = [\n",
    "    f for f in os.listdir(not_fractured_img_dir)\n",
    "    if f.endswith((\".jpg\", \".png\", \".jpeg\")) and is_valid_image(os.path.join(not_fractured_img_dir, f))\n",
    "]\n",
    "\n",
    "# Process each dataset split\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    img_src_dir = os.path.join(raw_data_dir, split, \"img\")\n",
    "    img_dest_dir_fractured = os.path.join(classification_data_dir, split, \"fractured\")\n",
    "    img_dest_dir_not_fractured = os.path.join(classification_data_dir, split, \"not_fractured\")\n",
    "\n",
    "    # Get valid fractured images\n",
    "    image_files = [\n",
    "        f for f in os.listdir(img_src_dir)\n",
    "        if f.endswith((\".jpg\", \".png\", \".jpeg\")) and is_valid_image(os.path.join(img_src_dir, f))\n",
    "    ]\n",
    "    fractured_count = len(image_files)\n",
    "\n",
    "    # Copy fractured images\n",
    "    for img_name in image_files:\n",
    "        img_path = os.path.join(img_src_dir, img_name)\n",
    "        shutil.copy(img_path, img_dest_dir_fractured)\n",
    "\n",
    "    # Process 'not fractured' images\n",
    "    available_images = list(set(all_not_fractured) - used_not_fractured)\n",
    "    num_to_sample = min(fractured_count, len(available_images))\n",
    "    if num_to_sample == 0:\n",
    "        print(f\"Warning: No valid 'not fractured' images available for {split}\")\n",
    "        continue\n",
    "\n",
    "    selected_images = random.sample(available_images, num_to_sample)\n",
    "\n",
    "    for img_name in selected_images:\n",
    "        used_not_fractured.add(img_name)\n",
    "        img_path = os.path.join(not_fractured_img_dir, img_name)\n",
    "        shutil.copy(img_path, img_dest_dir_not_fractured)\n",
    "\n",
    "print(\"Dataset conversion for image classification completed successfully. Corrupt images were skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>Fractured</th>\n",
       "      <th>Not Fractured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>574</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Split  Fractured  Not Fractured\n",
       "0  train        574            574\n",
       "1    val         82             82\n",
       "2   test         61             61"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Control: Count images in each split\n",
    "data_counts = {\"Split\": [], \"Fractured\": [], \"Not Fractured\": []}\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    fractured_dir = os.path.join(classification_data_dir, split, \"fractured\")\n",
    "    not_fractured_dir = os.path.join(classification_data_dir, split, \"not_fractured\")\n",
    "\n",
    "    num_fractured = len([f for f in os.listdir(fractured_dir) if f.endswith((\".jpg\", \".png\", \".jpeg\"))])\n",
    "    num_not_fractured = len([f for f in os.listdir(not_fractured_dir) if f.endswith((\".jpg\", \".png\", \".jpeg\"))])\n",
    "\n",
    "    data_counts[\"Split\"].append(split)\n",
    "    data_counts[\"Fractured\"].append(num_fractured)\n",
    "    data_counts[\"Not Fractured\"].append(num_not_fractured)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_counts = pd.DataFrame(data_counts)\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
